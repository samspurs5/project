{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb327ee",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6296aa",
   "metadata": {},
   "source": [
    "The first part of the code sets up the pca_wavelet network, the training comes later. Most of this code comes from the original authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985217e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../segmentation_helper')\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import data_loader as dl\n",
    "import model_broker as mb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37602504",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2598a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"pets\"\n",
    "test_size=300\n",
    "loader = dl.DataLoader(IMAGE_SIZE=128,dataset=dataset)\n",
    "img_ds = loader.import_processed_img()\n",
    "seg_ds = loader.import_processed_seg()\n",
    "cardinality = int(img_ds.cardinality())\n",
    "\n",
    "img_test = img_ds.take(test_size)\n",
    "seg_test = seg_ds.take(test_size)\n",
    "img_train = img_ds.skip(test_size)\n",
    "seg_train = seg_ds.skip(test_size)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261bd0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((next(iter(seg_train))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7462e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaledtanh(x): \n",
    "    return tf.math.tanh(x*0.5)\n",
    "\n",
    "def scaledatanh(x):\n",
    "    return tf.math.atanh(x)*2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb70530",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_name = \"img\"\n",
    "img_broker = mb.ModelBroker(trainset=img_train,\n",
    "                            testset=img_test,\n",
    "                            dirname=dataset+\"_\"+model_name,\n",
    "                            keep_percent=0.1,\n",
    "                            count=3,\n",
    "                            sample_size=100,)\n",
    "                            #activity_regularizer = scaledtanh,\n",
    "                            #inverse_activity_regularizer=scaledatanh)\n",
    "\n",
    "imghead,imginvhead = img_broker.build_model()\n",
    "imghead,imginvhead = img_broker.load_model()    \n",
    "img_broker.check_build(imghead,imginvhead,img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81649a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = \"seg\"\n",
    "seg_broker = mb.ModelBroker(trainset=seg_train,\n",
    "                            testset=seg_test,\n",
    "                            dirname=dataset+\"_\"+model_name,\n",
    "                            keep_percent=0.1,\n",
    "                            count=3,\n",
    "                            sample_size=100)\n",
    "                            #activity_regularizer = scaledtanh,\n",
    "                            #inverse_activity_regularizer=scaledatanh)\n",
    "\n",
    "seghead,seginvhead = seg_broker.build_model()\n",
    "seghead,seginvhead = seg_broker.load_model()    \n",
    "seg_broker.check_build(seghead,seginvhead,seg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b983f2c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424e726f",
   "metadata": {},
   "source": [
    "This is the loop used to find the variables to find A and b in y=Ax+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fae39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgflat = np.prod(imghead(next(iter(img_train))[0]).shape)\n",
    "segflat = np.prod(seghead(next(iter(seg_train))[0]).shape)\n",
    "end_shape = next(iter(seg_train))[0].shape\n",
    "n = 0.0\n",
    "\n",
    "xxt = np.zeros([imgflat])\n",
    "yxt = np.zeros([segflat])\n",
    "x = np.zeros([imgflat])\n",
    "y = np.zeros([segflat]) \n",
    "\n",
    "bar = tqdm.notebook.tqdm(total = int(img_train.cardinality()))\n",
    "\n",
    "for item in iter(zip(img_train,seg_train)):\n",
    "\n",
    "    bar.update(1)\n",
    "\n",
    "    image = item[0][0]\n",
    "    segmentation = item[1][0]\n",
    "\n",
    "    imgdecom = imghead(image)\n",
    "    segdecom = seghead(segmentation)\n",
    "\n",
    "    mat = tf.reshape(imgdecom,[-1])\n",
    "    segmat = tf.reshape(segdecom,[-1])\n",
    "\n",
    "    cov = tf.matmul([mat],[mat],transpose_a=True)\n",
    "    xxt += cov\n",
    "    segcov = tf.matmul([mat],[segmat],transpose_a=True)\n",
    "    yxt += segcov\n",
    "    x+=mat\n",
    "    y+=segmat\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c3c20",
   "metadata": {},
   "source": [
    "## Calculating A and B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d43fb5",
   "metadata": {},
   "source": [
    "This section uses the values found in the training loop to calculate values for A and B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aeb210",
   "metadata": {},
   "outputs": [],
   "source": [
    "xxt = xxt - tf.matmul([x],[x],transpose_a=True)/n\n",
    "yxt = yxt - tf.matmul([x],[y],transpose_a=True)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d9e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_xxt = tf.linalg.pinv(xxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729db57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.linalg.matmul(inverse_xxt,yxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecc01a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (y - tf.linalg.matvec(A,x,transpose_a=True))/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eecb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred,smooth=1):\n",
    "    y_true_f = tf.reshape(y_true,-1)\n",
    "    y_pred_f =tf.reshape(y_pred,-1)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f,0)\n",
    "\n",
    "    return float((2. * intersection+smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)+smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ffedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_coef(y_true, y_pred,smooth=1):\n",
    "  intersection = tf.reduce_sum(y_true * y_pred, 0)\n",
    "  union = tf.reduce_sum(y_true,0)+tf.reduce_sum(y_pred,0)-intersection\n",
    "  iou = tf.reduce_mean((intersection+1) / (union+1), 0)\n",
    "  return float(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e7dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "threshold_intensity = 0.1\n",
    "reconstruct = seghead(next(iter(seg_train))[0]).shape\n",
    "skip = random.randint(0,300)\n",
    "image,seg_base = next(iter(zip(img_train.skip(skip),seg_train.skip(skip))))\n",
    "imgdecom = imghead(image[0])\n",
    "imgdecom = tf.reshape(imgdecom,(1,-1))\n",
    "segdecom = tf.linalg.matvec(A,imgdecom,transpose_a=True)+b\n",
    "seg = seginvhead(tf.reshape(segdecom,(reconstruct)))\n",
    "\n",
    "y_true = tf.cast(tf.reduce_min(seg_base[0],2)==0,tf.float64)\n",
    "y_pred = tf.cast(tf.reduce_min(seg[0],2)<=threshold_intensity,tf.float64)\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(np.hstack([image[0],seg_base[0],seg[0]]))\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(np.hstack([y_true,y_pred]))\n",
    "print(dice_coef(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ffbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for split in [\"train\",\"test\"]:\n",
    "    if split == \"train\":\n",
    "        img_ds, seg_ds = (img_train,seg_train)\n",
    "    else:\n",
    "        img_ds, seg_ds = (img_test,seg_test)\n",
    "    n = int(seg_ds.cardinality())\n",
    "    dice_coeff_vals = []\n",
    "    for image,seg_base in iter(zip(img_ds, seg_ds)):\n",
    "        imgdecom = imghead(image[0])\n",
    "        imgdecom = tf.reshape(imgdecom,(1,-1))\n",
    "        segdecom = tf.linalg.matvec(A,imgdecom,transpose_a=True)+b\n",
    "        seg = seginvhead(tf.reshape(segdecom,(reconstruct)))\n",
    "        y_true = tf.cast(tf.reduce_min(seg_base[0],2)==0,tf.float64)\n",
    "        y_pred = tf.cast(tf.reduce_min(seg[0],2)<=threshold_intensity,tf.float64)\n",
    "        dice_coeff_vals.append(dice_coef(y_true,y_pred))\n",
    "    dice_coeff_mean = sum(dice_coeff_vals)/n\n",
    "    dice_coeff_std = (sum([((x - dice_coeff_mean) ** 2) for x in dice_coeff_vals]) / n)**0.5\n",
    "    np.save(f\"PCWN_CONV_{dataset}_{split}\",dice_coeff_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
