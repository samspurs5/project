{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb327ee",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6296aa",
   "metadata": {},
   "source": [
    "The first part of the code sets up the pca_wavelet network, the training comes later. Most of this code comes from the original authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "985217e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device not found\n",
      "Found GPU at: \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.append('../segmentation_helper')\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import data_loader as dl\n",
    "import model_broker as mb\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "tf.keras.backend.set_floatx(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0f0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaledtanh(x): \n",
    "    return tf.math.tanh(x*0.5)\n",
    "\n",
    "def scaledatanh(x):\n",
    "    return tf.math.atanh(x)*2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26b29c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_calculate_A_and_b(imghead, seghead, img_train,seg_train):\n",
    "    n = 0.0\n",
    "\n",
    "    imdecom_shape = imghead(next(iter(img_train))[0]).shape\n",
    "    img_channels = imdecom_shape[3] # shape_0\n",
    "    imdecom_2d_shape = imdecom_shape[1]*imdecom_shape[2] #shape_1\n",
    "\n",
    "    seg_channels = segdecom_shape[3] # shape_0\n",
    "    segdecom_2d_shape = segdecom_shape[1]*segdecom_shape[2] #shape_1\n",
    "    segdecom_shape = seghead(next(iter(seg_train))[0]).shape\n",
    "\n",
    "    xxt = np.zeros([img_channels,img_channels])\n",
    "    yxt = np.zeros([img_channels,seg_channels])\n",
    "    x = np.ones([imdecom_2d_shape])\n",
    "    x_m = np.zeros([img_channels])\n",
    "    y = np.ones([segdecom_2d_shape]) \n",
    "    y_m = np.zeros([seg_channels])\n",
    "\n",
    "    bar = tqdm.notebook.tqdm(total = int(img_train.cardinality()))\n",
    "\n",
    "    for item in iter(zip(img_train,seg_train)):\n",
    "        bar.update(1)\n",
    "        image = item[0][0]\n",
    "        segmentation = item[1][0]\n",
    "\n",
    "        imgdecom = imghead(image)\n",
    "        segdecom = seghead(segmentation)\n",
    "\n",
    "        mat = tf.reshape(imgdecom,[-1,seg_channels])\n",
    "        segmat = tf.reshape(segdecom,[-1,img_channels])\n",
    "\n",
    "        cov = tf.tensordot(mat,mat,[0,0])\n",
    "        xxt += cov\n",
    "        #del cov\n",
    "\n",
    "        segcov = tf.tensordot(mat,segmat,[0,0])\n",
    "        yxt += segcov\n",
    "        #del segcov\n",
    "\n",
    "        x_m += tf.linalg.matvec(mat,x,transpose_a=True)\n",
    "        y_m += tf.linalg.matvec(segmat,y,transpose_a=True)\n",
    "\n",
    "        n += 1\n",
    "    return A,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fae39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_calculate_A_and_b(imghead, seghead, img_train,seg_train):\n",
    "    imgflat = np.prod(imghead(next(iter(img_train))[0]).shape)\n",
    "    segflat = np.prod(seghead(next(iter(seg_train))[0]).shape)\n",
    "    end_shape = next(iter(seg_train))[0].shape\n",
    "    n = 0.0\n",
    "\n",
    "    xxt = np.zeros([imgflat])\n",
    "    yxt = np.zeros([segflat])\n",
    "    x = np.zeros([imgflat])\n",
    "    y = np.zeros([segflat]) \n",
    "\n",
    "    bar = tqdm.notebook.tqdm(total = int(img_train.cardinality()))\n",
    "\n",
    "    for item in iter(zip(img_train,seg_train)):\n",
    "\n",
    "        bar.update(1)\n",
    "\n",
    "        image = item[0][0]\n",
    "        segmentation = item[1][0]\n",
    "\n",
    "        imgdecom = imghead(image)\n",
    "        segdecom = seghead(segmentation)\n",
    "\n",
    "        mat = tf.reshape(imgdecom,[-1])\n",
    "        segmat = tf.reshape(segdecom,[-1])\n",
    "\n",
    "        cov = tf.matmul([mat],[mat],transpose_a=True)\n",
    "        xxt += cov\n",
    "        segcov = tf.matmul([mat],[segmat],transpose_a=True)\n",
    "        yxt += segcov\n",
    "        x+=mat\n",
    "        y+=segmat\n",
    "        n += 1\n",
    "        \n",
    "    print(\"loop calculated\")\n",
    "    xxt = xxt - tf.matmul([x],[x],transpose_a=True)/n\n",
    "    yxt = yxt - tf.matmul([x],[y],transpose_a=True)/n\n",
    "    print(\"calculating inverse\")\n",
    "    inverse_xxt = tf.linalg.pinv(xxt)\n",
    "    print(\"calculating A\")\n",
    "    A = tf.linalg.matmul(inverse_xxt,yxt)\n",
    "    print(\"calculating b\")\n",
    "    b = (y - tf.linalg.matvec(A,x,transpose_a=True))/n\n",
    "    return A,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28e5f4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_instance(train,\n",
    "                test,\n",
    "                dataset,\n",
    "                model_name,\n",
    "                keep_percent=1.0,\n",
    "                count=3,\n",
    "                sample_size=100,\n",
    "                activity_regularizer=None,\n",
    "                inverse_activity_regularizer=None,\n",
    "                activation_before=False,\n",
    "                check_build=False):\n",
    "    \n",
    "    stats = None\n",
    "    \n",
    "    broker = mb.ModelBroker(trainset=train,\n",
    "                                testset=test,\n",
    "                                dirname=dataset+\"_\"+model_name,\n",
    "                                keep_percent=keep_percent,\n",
    "                                count=count,\n",
    "                                sample_size=sample_size,\n",
    "                                activity_regularizer = activity_regularizer,\n",
    "                                inverse_activity_regularizer=inverse_activity_regularizer,\n",
    "                                activation_before=activation_before)\n",
    "    \n",
    "    head,invhead = broker.build_model()\n",
    "    head,invhead = broker.load_model()    \n",
    "    if check_build:\n",
    "        train_psnr,train_ncc = broker.check_build(head,invhead,train,stats_only=True)\n",
    "        test_psnr,test_ncc = broker.check_build(head,invhead,test,stats_only=True)\n",
    "        stats = (train_psnr,train_ncc,test_psnr,test_ncc)\n",
    "    return head,invhead, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fa6fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_metric_calculate(img_ds,seg_ds):\n",
    "    threshold_intensity = 0.01\n",
    "    dice_coeff_vals = []\n",
    "    iou_coeff_vals = []\n",
    "    n = 0\n",
    "    for image,seg_base in iter(zip(img_train,seg_train)):\n",
    "        imgdecom = imghead(image[0])\n",
    "        conv = tf.nn.conv2d(imgdecom, A_filter,1,\"VALID\")\n",
    "        conv = tf.nn.bias_add(conv,b)\n",
    "        seg = seginvhead(conv)\n",
    "        y_true = tf.cast(tf.reduce_min(seg_base[0],2)==0,tf.float64)\n",
    "        y_pred = tf.cast(tf.reduce_min(seg[0],2)<threshold_intensity,tf.float64)\n",
    "        dice_coeff_vals.append(dice_coef(y_true,y_pred))\n",
    "        iou_coeff_vals.append(iou_coef(y_true,y_pred))\n",
    "        n+=1\n",
    "    return iou_coeff_vals,dice_coeff_vals,n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24b5104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_metric_calculate(img_ds,seg_ds):\n",
    "    threshold_intensity = 0.01\n",
    "    dice_coeff_vals = []\n",
    "    iou_coeff_vals = []\n",
    "    n = 0\n",
    "    reconstruct = seghead(next(iter(seg_ds))[0]).shape\n",
    "    for image,seg_base in iter(zip(img_ds,seg_ds)):\n",
    "        imgdecom = imghead(image[0])\n",
    "        imgdecom = tf.reshape(imgdecom,(1,-1))\n",
    "        segdecom = tf.linalg.matvec(A,imgdecom,transpose_a=True)+b\n",
    "        seg = seginvhead(tf.reshape(segdecom,(reconstruct)))\n",
    "        y_true = tf.cast(tf.reduce_min(seg_base[0],2)==0,tf.float64)\n",
    "        y_pred = tf.cast(tf.reduce_min(seg[0],2)<threshold_intensity,tf.float64)\n",
    "        dice_coeff_vals.append(dice_coef(y_true,y_pred))\n",
    "        iou_coeff_vals.append(iou_coef(y_true,y_pred))\n",
    "        n+=1\n",
    "    return iou_coeff_vals,dice_coeff_vals,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2abf0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(seg_ds,img_ds,imghead,seghead,seginvhead, method):\n",
    "    iou_coeff_vals,dice_coeff_vals,n = method(img_ds,seg_ds)\n",
    "    dice_coeff_mean = sum(dice_coeff_vals)/n\n",
    "    iou_coeff_mean = sum(iou_coeff_vals)/n\n",
    "    dice_coeff_std = (sum([((x - dice_coeff_mean) ** 2) for x in dice_coeff_vals]) / n)**0.5\n",
    "    iou_coeff_std = (sum([((x - iou_coeff_mean) ** 2) for x in iou_coeff_vals]) / n)**0.5\n",
    "    return dice_coeff_mean, iou_coeff_mean, dice_coeff_std, iou_coeff_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a815a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred,smooth=1):\n",
    "    y_true_f = tf.reshape(y_true,-1)\n",
    "    y_pred_f =tf.reshape(y_pred,-1)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f,0)\n",
    "\n",
    "    return float((2. * intersection+smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)+smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "884d7b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_coef(y_true, y_pred,smooth=1):\n",
    "  intersection = tf.reduce_sum(y_true * y_pred, 0)\n",
    "  union = tf.reduce_sum(y_true,0)+tf.reduce_sum(y_pred,0)-intersection\n",
    "  iou = tf.reduce_mean((intersection+1) / (union+1), 0)\n",
    "  return float(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "161dcc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_exp = [(\"count\",i) for i in range(3,5)]\n",
    "keep_percents_exp = [(\"keep_percent\",i/10) for i in range(1,5)]\n",
    "train_sizes_exp = [(\"train_size\",i*2000) for i in range(1,4)]\n",
    "res_exp = []#[(\"res\",2**i) for i in range(6,9)]\n",
    "experiments = counts_exp + keep_percents_exp + train_sizes_exp + res_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb70530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789f718443be4468aac734a40a2c00b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-48d2f0bf6cc9>:18: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  record = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_percent 0.20629283704945683\n",
      "meanimg.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "Starting level 0\n",
      "Completing 64.0\n",
      "pca shape tf.Tensor([27 27], shape=(2,), dtype=int32)\n",
      "keep_channels 5 keep_max 12.0\n",
      "keep_channels 5\n",
      "ufilts.shape (1, 1, 1, 27, 5)\n",
      "end loop 64.0\n",
      "Starting level 1\n",
      "Completing 32.0\n",
      "pca shape tf.Tensor([45 45], shape=(2,), dtype=int32)\n",
      "keep_channels 9 keep_max 80.0\n",
      "keep_channels 9\n",
      "ufilts.shape (1, 1, 1, 45, 9)\n",
      "end loop 32.0\n",
      "Starting level 2\n",
      "Completing 16.0\n",
      "pca shape tf.Tensor([81 81], shape=(2,), dtype=int32)\n",
      "keep_channels 16 keep_max 576.0\n",
      "keep_channels 16\n",
      "ufilts.shape (1, 1, 1, 81, 16)\n",
      "end loop 16.0\n",
      "saving to: models/pets_img\n",
      "out.shape (1, 16, 16, 16)\n",
      "keep_percent 0.20629283704945683\n",
      "meanimg.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "Starting level 0\n",
      "Completing 64.0\n",
      "pca shape tf.Tensor([27 27], shape=(2,), dtype=int32)\n",
      "keep_channels 5 keep_max 12.0\n",
      "keep_channels 5\n",
      "ufilts.shape (1, 1, 1, 27, 5)\n",
      "end loop 64.0\n",
      "Starting level 1\n",
      "Completing 32.0\n",
      "pca shape tf.Tensor([45 45], shape=(2,), dtype=int32)\n",
      "keep_channels 9 keep_max 80.0\n",
      "keep_channels 9\n",
      "ufilts.shape (1, 1, 1, 45, 9)\n",
      "end loop 32.0\n",
      "Starting level 2\n",
      "Completing 16.0\n",
      "pca shape tf.Tensor([81 81], shape=(2,), dtype=int32)\n",
      "keep_channels 16 keep_max 576.0\n",
      "keep_channels 16\n",
      "ufilts.shape (1, 1, 1, 81, 16)\n",
      "end loop 16.0\n",
      "sample.shape (128, 128, 3)\n",
      "after reshape: sample.shape (1, 128, 128, 3)\n",
      "loading from: models/pets_img\n",
      "out.shape (1, 16, 16, 16)\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(128, 128, 3), dtype=float64, numpy=\n",
      "array([[[0.75257689, 0.6329248 , 0.51152802],\n",
      "        [0.80355394, 0.67678201, 0.53089267],\n",
      "        [0.8363238 , 0.71473986, 0.5422368 ],\n",
      "        ...,\n",
      "        [0.7453891 , 0.68484151, 0.59893322],\n",
      "        [0.79147881, 0.66086167, 0.5059247 ],\n",
      "        [0.87138146, 0.75016683, 0.58671206]],\n",
      "\n",
      "       [[0.79103935, 0.6632157 , 0.54447073],\n",
      "        [0.80558962, 0.67709655, 0.52565682],\n",
      "        [0.7719363 , 0.65932906, 0.51291245],\n",
      "        ...,\n",
      "        [0.71955758, 0.63062316, 0.53655267],\n",
      "        [0.8280946 , 0.68232256, 0.54134595],\n",
      "        [0.91678393, 0.78020835, 0.64809018]],\n",
      "\n",
      "       [[0.76215845, 0.64369255, 0.49240434],\n",
      "        [0.83149129, 0.71384424, 0.56482464],\n",
      "        [0.8471536 , 0.73336279, 0.56863344],\n",
      "        ...,\n",
      "        [0.58904696, 0.43896008, 0.2372956 ],\n",
      "        [0.83756989, 0.70129973, 0.52172375],\n",
      "        [0.90942645, 0.77951616, 0.6313836 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.67408615, 0.57938206, 0.36857191],\n",
      "        [0.47982442, 0.31608072, 0.22587055],\n",
      "        [0.55301565, 0.39230454, 0.3271355 ],\n",
      "        ...,\n",
      "        [0.71302229, 0.55107516, 0.4494746 ],\n",
      "        [0.54773003, 0.4696033 , 0.26832491],\n",
      "        [0.34478042, 0.31717408, 0.21933906]],\n",
      "\n",
      "       [[0.55286437, 0.47079027, 0.30843818],\n",
      "        [0.44521463, 0.34649682, 0.2380711 ],\n",
      "        [0.38266194, 0.41434374, 0.24368274],\n",
      "        ...,\n",
      "        [0.65062189, 0.67848116, 0.48200181],\n",
      "        [0.69992554, 0.71710873, 0.50854015],\n",
      "        [0.6623351 , 0.67425108, 0.4875814 ]],\n",
      "\n",
      "       [[0.86307728, 0.78543341, 0.7094956 ],\n",
      "        [0.55808562, 0.47897232, 0.4182457 ],\n",
      "        [0.38636857, 0.29732284, 0.18532333],\n",
      "        ...,\n",
      "        [0.58716106, 0.56941062, 0.45999229],\n",
      "        [0.61852098, 0.50776005, 0.35645396],\n",
      "        [0.83524936, 0.81492394, 0.70068407]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(128, 128, 3), dtype=float64, numpy=\n",
      "array([[[0.75257689, 0.6329248 , 0.51152802],\n",
      "        [0.80355394, 0.67678201, 0.53089267],\n",
      "        [0.8363238 , 0.71473986, 0.5422368 ],\n",
      "        ...,\n",
      "        [0.7453891 , 0.68484151, 0.59893322],\n",
      "        [0.79147881, 0.66086167, 0.5059247 ],\n",
      "        [0.87138146, 0.75016683, 0.58671206]],\n",
      "\n",
      "       [[0.79103935, 0.6632157 , 0.54447073],\n",
      "        [0.80558962, 0.67709655, 0.52565682],\n",
      "        [0.7719363 , 0.65932906, 0.51291245],\n",
      "        ...,\n",
      "        [0.71955758, 0.63062316, 0.53655267],\n",
      "        [0.8280946 , 0.68232256, 0.54134595],\n",
      "        [0.91678393, 0.78020835, 0.64809018]],\n",
      "\n",
      "       [[0.76215845, 0.64369255, 0.49240434],\n",
      "        [0.83149129, 0.71384424, 0.56482464],\n",
      "        [0.8471536 , 0.73336279, 0.56863344],\n",
      "        ...,\n",
      "        [0.58904696, 0.43896008, 0.2372956 ],\n",
      "        [0.83756989, 0.70129973, 0.52172375],\n",
      "        [0.90942645, 0.77951616, 0.6313836 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.67408615, 0.57938206, 0.36857191],\n",
      "        [0.47982442, 0.31608072, 0.22587055],\n",
      "        [0.55301565, 0.39230454, 0.3271355 ],\n",
      "        ...,\n",
      "        [0.71302229, 0.55107516, 0.4494746 ],\n",
      "        [0.54773003, 0.4696033 , 0.26832491],\n",
      "        [0.34478042, 0.31717408, 0.21933906]],\n",
      "\n",
      "       [[0.55286437, 0.47079027, 0.30843818],\n",
      "        [0.44521463, 0.34649682, 0.2380711 ],\n",
      "        [0.38266194, 0.41434374, 0.24368274],\n",
      "        ...,\n",
      "        [0.65062189, 0.67848116, 0.48200181],\n",
      "        [0.69992554, 0.71710873, 0.50854015],\n",
      "        [0.6623351 , 0.67425108, 0.4875814 ]],\n",
      "\n",
      "       [[0.86307728, 0.78543341, 0.7094956 ],\n",
      "        [0.55808562, 0.47897232, 0.4182457 ],\n",
      "        [0.38636857, 0.29732284, 0.18532333],\n",
      "        ...,\n",
      "        [0.58716106, 0.56941062, 0.45999229],\n",
      "        [0.61852098, 0.50776005, 0.35645396],\n",
      "        [0.83524936, 0.81492394, 0.70068407]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(128, 128, 3), dtype=float64, numpy=\n",
      "array([[[0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        ...,\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569]],\n",
      "\n",
      "       [[0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.23937032, 0.4215574 , 0.18896006],\n",
      "        [0.22728512, 0.42014661, 0.19209871],\n",
      "        ...,\n",
      "        [0.24852918, 0.45332271, 0.2013016 ],\n",
      "        [0.25310513, 0.43315765, 0.21225035],\n",
      "        [0.03921569, 0.03921569, 0.03921569]],\n",
      "\n",
      "       [[0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        ...,\n",
      "        [0.03921569, 0.04090313, 0.03921569],\n",
      "        [0.03921569, 0.03949095, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        ...,\n",
      "        [0.04118437, 0.04005941, 0.04535295],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569]],\n",
      "\n",
      "       [[0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.2523672 , 0.44010895, 0.20303789],\n",
      "        [0.2278464 , 0.45626366, 0.19595684],\n",
      "        ...,\n",
      "        [0.25473419, 0.46940944, 0.20471862],\n",
      "        [0.23275746, 0.43166503, 0.2151494 ],\n",
      "        [0.03921569, 0.03921569, 0.03921569]],\n",
      "\n",
      "       [[0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        ...,\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(128, 128, 3), dtype=float64, numpy=\n",
      "array([[[0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        ...,\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569]],\n",
      "\n",
      "       [[0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.23937032, 0.4215574 , 0.18896006],\n",
      "        [0.22728512, 0.42014661, 0.19209871],\n",
      "        ...,\n",
      "        [0.24852918, 0.45332271, 0.2013016 ],\n",
      "        [0.25310513, 0.43315765, 0.21225035],\n",
      "        [0.03921569, 0.03921569, 0.03921569]],\n",
      "\n",
      "       [[0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        ...,\n",
      "        [0.03921569, 0.04090313, 0.03921569],\n",
      "        [0.03921569, 0.03949095, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        ...,\n",
      "        [0.04118437, 0.04005941, 0.04535295],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569]],\n",
      "\n",
      "       [[0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.2523672 , 0.44010895, 0.20303789],\n",
      "        [0.2278464 , 0.45626366, 0.19595684],\n",
      "        ...,\n",
      "        [0.25473419, 0.46940944, 0.20471862],\n",
      "        [0.23275746, 0.43166503, 0.2151494 ],\n",
      "        [0.03921569, 0.03921569, 0.03921569]],\n",
      "\n",
      "       [[0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        ...,\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569],\n",
      "        [0.03921569, 0.03921569, 0.03921569]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_percent 0.20629283704945683\n",
      "meanimg.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "Starting level 0\n",
      "Completing 64.0\n",
      "pca shape tf.Tensor([27 27], shape=(2,), dtype=int32)\n",
      "keep_channels 5 keep_max 12.0\n",
      "keep_channels 5\n",
      "ufilts.shape (1, 1, 1, 27, 5)\n",
      "end loop 64.0\n",
      "Starting level 1\n",
      "Completing 32.0\n",
      "pca shape tf.Tensor([45 45], shape=(2,), dtype=int32)\n",
      "keep_channels 9 keep_max 80.0\n",
      "keep_channels 9\n",
      "ufilts.shape (1, 1, 1, 45, 9)\n",
      "end loop 32.0\n",
      "Starting level 2\n",
      "Completing 16.0\n",
      "pca shape tf.Tensor([81 81], shape=(2,), dtype=int32)\n",
      "keep_channels 16 keep_max 576.0\n",
      "keep_channels 16\n",
      "ufilts.shape (1, 1, 1, 81, 16)\n",
      "end loop 16.0\n",
      "saving to: models/pets_seg\n",
      "out.shape (1, 16, 16, 16)\n",
      "keep_percent 0.20629283704945683\n",
      "meanimg.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "Starting level 0\n",
      "Completing 64.0\n",
      "pca shape tf.Tensor([27 27], shape=(2,), dtype=int32)\n",
      "keep_channels 5 keep_max 12.0\n",
      "keep_channels 5\n",
      "ufilts.shape (1, 1, 1, 27, 5)\n",
      "end loop 64.0\n",
      "Starting level 1\n",
      "Completing 32.0\n",
      "pca shape tf.Tensor([45 45], shape=(2,), dtype=int32)\n",
      "keep_channels 9 keep_max 80.0\n",
      "keep_channels 9\n",
      "ufilts.shape (1, 1, 1, 45, 9)\n",
      "end loop 32.0\n",
      "Starting level 2\n",
      "Completing 16.0\n",
      "pca shape tf.Tensor([81 81], shape=(2,), dtype=int32)\n",
      "keep_channels 16 keep_max 576.0\n",
      "keep_channels 16\n",
      "ufilts.shape (1, 1, 1, 81, 16)\n",
      "end loop 16.0\n",
      "sample.shape (128, 128, 3)\n",
      "after reshape: sample.shape (1, 128, 128, 3)\n",
      "loading from: models/pets_seg\n",
      "out.shape (1, 16, 16, 16)\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(128, 128, 3), dtype=float64, numpy=\n",
      "array([[[0.9215619 , 0.93773502, 0.95513868],\n",
      "        [0.93311363, 0.94665527, 0.96270919],\n",
      "        [0.91230255, 0.92977417, 0.94153887],\n",
      "        ...,\n",
      "        [0.97255594, 0.97256434, 0.98040748],\n",
      "        [0.97020501, 0.97627145, 0.98695356],\n",
      "        [0.97112608, 0.97504765, 0.98289078]],\n",
      "\n",
      "       [[0.92536259, 0.94020659, 0.94943345],\n",
      "        [0.92122996, 0.93691623, 0.94868094],\n",
      "        [0.88733751, 0.90299743, 0.91479278],\n",
      "        ...,\n",
      "        [0.96360296, 0.9750613 , 0.98039216],\n",
      "        [0.95545346, 0.97113973, 0.9750613 ],\n",
      "        [0.95495296, 0.97063923, 0.9745608 ]],\n",
      "\n",
      "       [[0.92078739, 0.9443168 , 0.9443168 ],\n",
      "        [0.9254902 , 0.94117647, 0.95294118],\n",
      "        [0.9294005 , 0.94509804, 0.95686275],\n",
      "        ...,\n",
      "        [0.96863151, 0.97646344, 0.9725756 ],\n",
      "        [0.9691636 , 0.97466302, 0.97777271],\n",
      "        [0.96491343, 0.96961623, 0.97511566]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.81596899, 0.44522753, 0.03921569],\n",
      "        [0.83071268, 0.43768814, 0.03921569],\n",
      "        [0.81676269, 0.42514911, 0.03921569],\n",
      "        ...,\n",
      "        [0.75086194, 0.73229575, 0.72260624],\n",
      "        [0.7494387 , 0.73375243, 0.72198772],\n",
      "        [0.76309049, 0.74348265, 0.73114425]],\n",
      "\n",
      "       [[0.8302086 , 0.47712451, 0.03921569],\n",
      "        [0.82297724, 0.45575908, 0.03921569],\n",
      "        [0.81471765, 0.43424457, 0.03921569],\n",
      "        ...,\n",
      "        [0.76862198, 0.74480271, 0.73444182],\n",
      "        [0.75130188, 0.73883271, 0.7284773 ],\n",
      "        [0.75326288, 0.75075066, 0.73788297]],\n",
      "\n",
      "       [[0.84687501, 0.53846174, 0.03921569],\n",
      "        [0.83983344, 0.51313311, 0.03921569],\n",
      "        [0.80968285, 0.4516781 , 0.03921569],\n",
      "        ...,\n",
      "        [0.76859683, 0.74937052, 0.74721897],\n",
      "        [0.77055258, 0.74097735, 0.74275428],\n",
      "        [0.76236212, 0.74901962, 0.74346232]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(128, 128, 3), dtype=float64, numpy=\n",
      "array([[[0.9215619 , 0.93773502, 0.95513868],\n",
      "        [0.93311363, 0.94665527, 0.96270919],\n",
      "        [0.91230255, 0.92977417, 0.94153887],\n",
      "        ...,\n",
      "        [0.97255594, 0.97256434, 0.98040748],\n",
      "        [0.97020501, 0.97627145, 0.98695356],\n",
      "        [0.97112608, 0.97504765, 0.98289078]],\n",
      "\n",
      "       [[0.92536259, 0.94020659, 0.94943345],\n",
      "        [0.92122996, 0.93691623, 0.94868094],\n",
      "        [0.88733751, 0.90299743, 0.91479278],\n",
      "        ...,\n",
      "        [0.96360296, 0.9750613 , 0.98039216],\n",
      "        [0.95545346, 0.97113973, 0.9750613 ],\n",
      "        [0.95495296, 0.97063923, 0.9745608 ]],\n",
      "\n",
      "       [[0.92078739, 0.9443168 , 0.9443168 ],\n",
      "        [0.9254902 , 0.94117647, 0.95294118],\n",
      "        [0.9294005 , 0.94509804, 0.95686275],\n",
      "        ...,\n",
      "        [0.96863151, 0.97646344, 0.9725756 ],\n",
      "        [0.9691636 , 0.97466302, 0.97777271],\n",
      "        [0.96491343, 0.96961623, 0.97511566]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.81596899, 0.44522753, 0.03921569],\n",
      "        [0.83071268, 0.43768814, 0.03921569],\n",
      "        [0.81676269, 0.42514911, 0.03921569],\n",
      "        ...,\n",
      "        [0.75086194, 0.73229575, 0.72260624],\n",
      "        [0.7494387 , 0.73375243, 0.72198772],\n",
      "        [0.76309049, 0.74348265, 0.73114425]],\n",
      "\n",
      "       [[0.8302086 , 0.47712451, 0.03921569],\n",
      "        [0.82297724, 0.45575908, 0.03921569],\n",
      "        [0.81471765, 0.43424457, 0.03921569],\n",
      "        ...,\n",
      "        [0.76862198, 0.74480271, 0.73444182],\n",
      "        [0.75130188, 0.73883271, 0.7284773 ],\n",
      "        [0.75326288, 0.75075066, 0.73788297]],\n",
      "\n",
      "       [[0.84687501, 0.53846174, 0.03921569],\n",
      "        [0.83983344, 0.51313311, 0.03921569],\n",
      "        [0.80968285, 0.4516781 , 0.03921569],\n",
      "        ...,\n",
      "        [0.76859683, 0.74937052, 0.74721897],\n",
      "        [0.77055258, 0.74097735, 0.74275428],\n",
      "        [0.76236212, 0.74901962, 0.74346232]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(128, 128, 3), dtype=float64, numpy=\n",
      "array([[[0.86446941, 0.86054784, 0.63744569],\n",
      "        [0.86661547, 0.86232626, 0.63346595],\n",
      "        [0.87126535, 0.86342221, 0.63633889],\n",
      "        ...,\n",
      "        [0.99001223, 0.99001223, 0.99001223],\n",
      "        [0.99215686, 0.99215686, 0.99215686],\n",
      "        [0.9939338 , 0.9939338 , 0.9939338 ]],\n",
      "\n",
      "       [[0.86085111, 0.86173433, 0.63228691],\n",
      "        [0.85776585, 0.86168742, 0.63561463],\n",
      "        [0.82080197, 0.82501465, 0.62198156],\n",
      "        ...,\n",
      "        [0.99356616, 0.99356616, 0.99356616],\n",
      "        [0.99466914, 0.99466914, 0.99466914],\n",
      "        [0.99416864, 0.99416864, 0.99416864]],\n",
      "\n",
      "       [[0.87293202, 0.87293202, 0.62403494],\n",
      "        [0.88223594, 0.88443631, 0.65145963],\n",
      "        [0.88156766, 0.88548923, 0.65227842],\n",
      "        ...,\n",
      "        [0.99111521, 0.99111521, 0.99111521],\n",
      "        [0.99111521, 0.99111521, 0.99111521],\n",
      "        [0.99111521, 0.99111521, 0.99111521]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.94486278, 0.9359588 , 0.59473085],\n",
      "        [0.97576904, 0.94715577, 0.67112076],\n",
      "        [0.84795642, 0.79831517, 0.55948728],\n",
      "        ...,\n",
      "        [0.69390512, 0.7534802 , 0.41774929],\n",
      "        [0.6828841 , 0.73587984, 0.30046797],\n",
      "        [0.65090066, 0.69871855, 0.23217583]],\n",
      "\n",
      "       [[0.7242561 , 0.63699257, 0.23910919],\n",
      "        [0.58859408, 0.53417039, 0.14866225],\n",
      "        [0.68080002, 0.6182093 , 0.16860017],\n",
      "        ...,\n",
      "        [0.63585854, 0.67615205, 0.28415576],\n",
      "        [0.66813898, 0.71237916, 0.32576859],\n",
      "        [0.73174119, 0.76153111, 0.37132904]],\n",
      "\n",
      "       [[0.93233955, 0.91233486, 0.63364166],\n",
      "        [0.53553492, 0.49365857, 0.20088848],\n",
      "        [0.74479169, 0.6880517 , 0.38544971],\n",
      "        ...,\n",
      "        [0.67978877, 0.71577364, 0.22163901],\n",
      "        [0.64184403, 0.71001697, 0.28759575],\n",
      "        [0.53931504, 0.57144153, 0.19910195]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(128, 128, 3), dtype=float64, numpy=\n",
      "array([[[0.86446941, 0.86054784, 0.63744569],\n",
      "        [0.86661547, 0.86232626, 0.63346595],\n",
      "        [0.87126535, 0.86342221, 0.63633889],\n",
      "        ...,\n",
      "        [0.99001223, 0.99001223, 0.99001223],\n",
      "        [0.99215686, 0.99215686, 0.99215686],\n",
      "        [0.9939338 , 0.9939338 , 0.9939338 ]],\n",
      "\n",
      "       [[0.86085111, 0.86173433, 0.63228691],\n",
      "        [0.85776585, 0.86168742, 0.63561463],\n",
      "        [0.82080197, 0.82501465, 0.62198156],\n",
      "        ...,\n",
      "        [0.99356616, 0.99356616, 0.99356616],\n",
      "        [0.99466914, 0.99466914, 0.99466914],\n",
      "        [0.99416864, 0.99416864, 0.99416864]],\n",
      "\n",
      "       [[0.87293202, 0.87293202, 0.62403494],\n",
      "        [0.88223594, 0.88443631, 0.65145963],\n",
      "        [0.88156766, 0.88548923, 0.65227842],\n",
      "        ...,\n",
      "        [0.99111521, 0.99111521, 0.99111521],\n",
      "        [0.99111521, 0.99111521, 0.99111521],\n",
      "        [0.99111521, 0.99111521, 0.99111521]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.94486278, 0.9359588 , 0.59473085],\n",
      "        [0.97576904, 0.94715577, 0.67112076],\n",
      "        [0.84795642, 0.79831517, 0.55948728],\n",
      "        ...,\n",
      "        [0.69390512, 0.7534802 , 0.41774929],\n",
      "        [0.6828841 , 0.73587984, 0.30046797],\n",
      "        [0.65090066, 0.69871855, 0.23217583]],\n",
      "\n",
      "       [[0.7242561 , 0.63699257, 0.23910919],\n",
      "        [0.58859408, 0.53417039, 0.14866225],\n",
      "        [0.68080002, 0.6182093 , 0.16860017],\n",
      "        ...,\n",
      "        [0.63585854, 0.67615205, 0.28415576],\n",
      "        [0.66813898, 0.71237916, 0.32576859],\n",
      "        [0.73174119, 0.76153111, 0.37132904]],\n",
      "\n",
      "       [[0.93233955, 0.91233486, 0.63364166],\n",
      "        [0.53553492, 0.49365857, 0.20088848],\n",
      "        [0.74479169, 0.6880517 , 0.38544971],\n",
      "        ...,\n",
      "        [0.67978877, 0.71577364, 0.22163901],\n",
      "        [0.64184403, 0.71001697, 0.28759575],\n",
      "        [0.53931504, 0.57144153, 0.19910195]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9ae1fce2334ee69bfcae5f611a30ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7049 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop calculated\n",
      "calculating inverse\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_size = 300\n",
    "\n",
    "#These are the standard experiment settings\n",
    "activity_regularizer = scaledtanh\n",
    "inverse_activity_regularizer = scaledatanh\n",
    "count = 3\n",
    "keep_percent = 0.1\n",
    "train_size = None\n",
    "res = 128\n",
    "dataset = \"pets\"\n",
    "\n",
    "calculate_A_and_b = connected_calculate_A_and_b\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for settings in tqdm.notebook.tqdm(experiments):\n",
    "    \n",
    "    record = pd.Series()\n",
    "    \n",
    "    variable, value = settings\n",
    "    if variable == \"count\":\n",
    "        count = value\n",
    "    if variable == \"keep_percent\":\n",
    "        keep_percent = value\n",
    "    if variable == \"train_size\":\n",
    "        train_size = value\n",
    "    if variable == \"res\":\n",
    "        resolution = value\n",
    "\n",
    "    loader = dl.DataLoader(IMAGE_SIZE=res,dataset=dataset,take=train_size)\n",
    "    img_ds = loader.import_processed_img()\n",
    "    seg_ds = loader.import_processed_seg()\n",
    "    cardinality = int(img_ds.cardinality())\n",
    "\n",
    "    img_test = img_ds.take(test_size)\n",
    "    seg_test = seg_ds.take(test_size)\n",
    "    img_train = img_ds.skip(test_size)\n",
    "    seg_train = seg_ds.skip(test_size)    \n",
    "    \n",
    "    record[\"count\"]=count\n",
    "    record[\"keep_percent\"] = keep_percent\n",
    "    record[\"activity_regularizer\"] = activity_regularizer != None\n",
    "    record[\"training_data_size\"] = train_size\n",
    "    \n",
    "    img_train_start = time.time()\n",
    "    imghead, imginvhead,stats = build_model_instance(img_train,img_test,dataset,\"img\",keep_percent = keep_percent,count=count,check_build=True)\n",
    "    psnr_train,ncc_train,psnr_test,ncc_test = stats\n",
    "    img_train_end = time.time()\n",
    "    \n",
    "    record[\"img_channel_size\"] = imghead(next(iter(img_train))[0]).shape[-1]\n",
    "    record[\"img_train_time\"] = img_train_end - img_train_start\n",
    "    record[\"train_img_psnr\"] = psnr_train\n",
    "    record[\"train_img_ncc\"] = ncc_train\n",
    "    record[\"test_img_psnr\"] = psnr_test\n",
    "    record[\"test_img_ncc\"] = ncc_test\n",
    "    \n",
    "    seg_train_start = time.time()\n",
    "    seghead, seginvhead,stats = build_model_instance(seg_train,seg_test,dataset,\"seg\",count=count,keep_percent = keep_percent,check_build=True)\n",
    "    psnr_train,ncc_train,psnr_test,ncc_test = stats\n",
    "    seg_train_end = time.time()\n",
    "    \n",
    "    record[\"seg_channel_size\"] = seghead(next(iter(seg_train))[0]).shape[-1]\n",
    "    record[\"seg_train_time\"] = img_train_end - img_train_start\n",
    "    record[\"train_seg_psnr\"] = psnr_train\n",
    "    record[\"train_seg_ncc\"] = ncc_train\n",
    "    record[\"test_seg_psnr\"] = psnr_test\n",
    "    record[\"test_seg_ncc\"] = ncc_test\n",
    "    \n",
    "    train_time_start = time.time()\n",
    "    A,b = calculate_A_and_b(imghead,seghead,img_train,seg_train)\n",
    "    train_time_end = time.time()\n",
    "    \n",
    "    record[\"linear_inverse_train_time\"] = train_time_end - train_time_start \n",
    "    \n",
    "    dice_mean_test, iou_mean_test, dice_std_test, iou_std_test = calculate_metrics(seg_test,img_test,imghead,seghead,seginvhead, conv_metric_calculate)\n",
    "    dice_mean_train, iou_mean_train, dice_std_train, iou_std_train = calculate_metrics(seg_train,img_train,imghead,seghead,seginvhead, connected_metric_calculate)\n",
    "    \n",
    "    record[\"dice_mean_train\"] = dice_mean_train\n",
    "    record[\"iou_mean_train\"] = iou_mean_train\n",
    "    record[\"dice_std_train\"] = dice_std_train\n",
    "    record[\"iou_std_train\"] = iou_std_train\n",
    "    record[\"dice_mean_test\"] = dice_mean_test\n",
    "    record[\"iou_mean_test\"] = iou_mean_test\n",
    "    record[\"dice_std_test\"] = dice_std_test\n",
    "    record[\"iou_std_test\"] = iou_std_test\n",
    "    \n",
    "    df = df.append(record,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d41765",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"formal_experiment_connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e7dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "reconstruct = seghead(next(iter(seg_train))[0]).shape\n",
    "threshold_intensity = 0.01\n",
    "skip = random.randint(0,70)\n",
    "image,seg_base = next(iter(zip(img_test.skip(skip),seg_test.skip(skip))))\n",
    "imgdecom = imghead(image[0])\n",
    "imgdecom = tf.reshape(imgdecom,(1,-1))\n",
    "segdecom = tf.linalg.matvec(A,imgdecom,transpose_a=True)+b\n",
    "seg = seginvhead(tf.reshape(segdecom,(reconstruct)))\n",
    "y_true = tf.cast(tf.reduce_min(seg_base[0],2)==0,tf.float64)\n",
    "y_pred = tf.cast(tf.reduce_min(seg[0],2)<threshold_intensity,tf.float64)\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(np.hstack([image[0],seg_base[0],seg[0]]))\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(np.hstack([y_true,y_pred]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8ff82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
