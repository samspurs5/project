{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abb327ee",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6296aa",
   "metadata": {},
   "source": [
    "The first part of the code sets up the pca_wavelet network, the training comes later. Most of this code comes from the original authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "985217e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device not found\n",
      "Found GPU at: \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.append('../segmentation_helper')\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import data_loader as dl\n",
    "import model_broker as mb\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "tf.keras.backend.set_floatx(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb0f0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaledtanh(x): \n",
    "    return tf.math.tanh(x*0.5)\n",
    "\n",
    "def scaledatanh(x):\n",
    "    return tf.math.atanh(x)*2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_calculate_A_and_b(imghead, seghead, img_train,seg_train):\n",
    "    n = 0.0\n",
    "\n",
    "    imdecom_shape = imghead(next(iter(img_train))[0]).shape\n",
    "    img_channels = imdecom_shape[3] # shape_0\n",
    "    imdecom_2d_shape = imdecom_shape[1]*imdecom_shape[2] #shape_1\n",
    "\n",
    "    seg_channels = segdecom_shape[3] # shape_0\n",
    "    segdecom_2d_shape = segdecom_shape[1]*segdecom_shape[2] #shape_1\n",
    "    segdecom_shape = seghead(next(iter(seg_train))[0]).shape\n",
    "\n",
    "    xxt = np.zeros([img_channels,img_channels])\n",
    "    yxt = np.zeros([img_channels,seg_channels])\n",
    "    x = np.ones([imdecom_2d_shape])\n",
    "    x_m = np.zeros([img_channels])\n",
    "    y = np.ones([segdecom_2d_shape]) \n",
    "    y_m = np.zeros([seg_channels])\n",
    "\n",
    "    bar = tqdm.notebook.tqdm(total = int(img_train.cardinality()))\n",
    "\n",
    "    for item in iter(zip(img_train,seg_train)):\n",
    "        bar.update(1)\n",
    "        image = item[0][0]\n",
    "        segmentation = item[1][0]\n",
    "\n",
    "        imgdecom = imghead(image)\n",
    "        segdecom = seghead(segmentation)\n",
    "\n",
    "        mat = tf.reshape(imgdecom,[-1,seg_channels])\n",
    "        segmat = tf.reshape(segdecom,[-1,img_channels])\n",
    "\n",
    "        cov = tf.tensordot(mat,mat,[0,0])\n",
    "        xxt += cov\n",
    "        #del cov\n",
    "\n",
    "        segcov = tf.tensordot(mat,segmat,[0,0])\n",
    "        yxt += segcov\n",
    "        #del segcov\n",
    "\n",
    "        x_m += tf.linalg.matvec(mat,x,transpose_a=True)\n",
    "        y_m += tf.linalg.matvec(segmat,y,transpose_a=True)\n",
    "\n",
    "        n += 1\n",
    "    return A,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85fae39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_calculate_A_and_b(imghead, seghead, img_train,seg_train):\n",
    "    imgflat = np.prod(imghead(next(iter(img_train))[0]).shape)\n",
    "    segflat = np.prod(seghead(next(iter(seg_train))[0]).shape)\n",
    "    end_shape = next(iter(seg_train))[0].shape\n",
    "    n = 0.0\n",
    "\n",
    "    xxt = np.zeros([imgflat])\n",
    "    yxt = np.zeros([segflat])\n",
    "    x = np.zeros([imgflat])\n",
    "    y = np.zeros([segflat]) \n",
    "\n",
    "    bar = tqdm.notebook.tqdm(total = int(img_train.cardinality()))\n",
    "\n",
    "    for item in iter(zip(img_train,seg_train)):\n",
    "\n",
    "        bar.update(1)\n",
    "\n",
    "        image = item[0][0]\n",
    "        segmentation = item[1][0]\n",
    "\n",
    "        imgdecom = imghead(image)\n",
    "        segdecom = seghead(segmentation)\n",
    "\n",
    "        mat = tf.reshape(imgdecom,[-1])\n",
    "        segmat = tf.reshape(segdecom,[-1])\n",
    "\n",
    "        cov = tf.matmul([mat],[mat],transpose_a=True)\n",
    "        xxt += cov\n",
    "        segcov = tf.matmul([mat],[segmat],transpose_a=True)\n",
    "        yxt += segcov\n",
    "        x+=mat\n",
    "        y+=segmat\n",
    "        n += 1\n",
    "        \n",
    "    print(\"loop calculated\")\n",
    "    xxt = xxt - tf.matmul([x],[x],transpose_a=True)/n\n",
    "    yxt = yxt - tf.matmul([x],[y],transpose_a=True)/n\n",
    "    print(\"calculating inverse\")\n",
    "    inverse_xxt = tf.linalg.pinv(xxt)\n",
    "    print(\"calculating A\")\n",
    "    A = tf.linalg.matmul(inverse_xxt,yxt)\n",
    "    print(\"calculating b\")\n",
    "    b = (y - tf.linalg.matvec(A,x,transpose_a=True))/n\n",
    "    return A,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e920dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_instance(train,\n",
    "                test,\n",
    "                dataset,\n",
    "                model_name,\n",
    "                keep_percent=1.0,\n",
    "                count=3,\n",
    "                sample_size=100,\n",
    "                activity_regularizer=None,\n",
    "                inverse_activity_regularizer=None,\n",
    "                activation_before=False,\n",
    "                check_build=False):\n",
    "    \n",
    "    stats = None\n",
    "    \n",
    "    broker = mb.ModelBroker(trainset=train,\n",
    "                                testset=test,\n",
    "                                dirname=dataset+\"_\"+model_name,\n",
    "                                keep_percent=keep_percent,\n",
    "                                count=count,\n",
    "                                sample_size=sample_size,\n",
    "                                activity_regularizer = activity_regularizer,\n",
    "                                inverse_activity_regularizer=inverse_activity_regularizer,\n",
    "                                activation_before=activation_before)\n",
    "    \n",
    "    head,invhead = broker.build_model()\n",
    "    head,invhead = broker.load_model()    \n",
    "    if check_build:\n",
    "        train_psnr,train_ncc = broker.check_build(head,invhead,train,stats_only=True)\n",
    "        test_psnr,test_ncc = broker.check_build(head,invhead,test,stats_only=True)\n",
    "        stats = (train_psnr,train_ncc,test_psnr,test_ncc)\n",
    "    return head,invhead, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f98b315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_metric_calculate():\n",
    "    threshold_intensity = 0.01\n",
    "    dice_coeff_vals = []\n",
    "    iou_coeff_vals = []\n",
    "    n = 0\n",
    "    for image,seg_base in iter(zip(img_train,seg_train)):\n",
    "        imgdecom = imghead(image[0])\n",
    "        conv = tf.nn.conv2d(imgdecom, A_filter,1,\"VALID\")\n",
    "        conv = tf.nn.bias_add(conv,b)\n",
    "        seg = seginvhead(conv)\n",
    "        y_true = tf.cast(tf.reduce_min(seg_base[0],2)==0,tf.float64)\n",
    "        y_pred = tf.cast(tf.reduce_min(seg[0],2)<threshold_intensity,tf.float64)\n",
    "        dice_coeff_vals.append(dice_coef(y_true,y_pred))\n",
    "        iou_coeff_vals.append(iou_coef(y_true,y_pred))\n",
    "        n+=1\n",
    "    return iou_coeff_vals,dice_coeff_vals,n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c0377f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connected_metric_calculate(img_ds,seg_ds):\n",
    "    threshold_intensity = 0.01\n",
    "    dice_coeff_vals = []\n",
    "    iou_coeff_vals = []\n",
    "    n = 0\n",
    "    reconstruct = seghead(next(iter(seg_ds))[0]).shape\n",
    "    for image,seg_base in iter(zip(img_ds,seg_ds)):\n",
    "        imgdecom = imghead(image[0])\n",
    "        imgdecom = tf.reshape(imgdecom,(1,-1))\n",
    "        segdecom = tf.linalg.matvec(A,imgdecom,transpose_a=True)+b\n",
    "        seg = seginvhead(tf.reshape(segdecom,(reconstruct)))\n",
    "        y_true = tf.cast(tf.reduce_min(seg_base[0],2)==0,tf.float64)\n",
    "        y_pred = tf.cast(tf.reduce_min(seg[0],2)<threshold_intensity,tf.float64)\n",
    "        dice_coeff_vals.append(dice_coef(y_true,y_pred))\n",
    "        iou_coeff_vals.append(iou_coef(y_true,y_pred))\n",
    "        n+=1\n",
    "    return iou_coeff_vals,dice_coeff_vals,n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63482e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(seg_ds,img_ds,imghead,seghead,seginvhead):\n",
    "    \n",
    "    iou_coeff_vals,dice_coeff_vals,n = connected_metric_calculate(img_ds,seg_ds)\n",
    "    #iou_coeff_vals,dice_coeff_vals,n = conv_metric_calculate(img_ds,seg_ds)\n",
    "    dice_coeff_mean = sum(dice_coeff_vals)/n\n",
    "    iou_coeff_mean = sum(iou_coeff_vals)/n\n",
    "    dice_coeff_std = (sum([((x - dice_coeff_mean) ** 2) for x in dice_coeff_vals]) / n)**0.5\n",
    "    iou_coeff_std = (sum([((x - iou_coeff_mean) ** 2) for x in iou_coeff_vals]) / n)**0.5\n",
    "    return dice_coeff_mean, iou_coeff_mean, dice_coeff_std, iou_coeff_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1b33af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred,smooth=1):\n",
    "    y_true_f = tf.reshape(y_true,-1)\n",
    "    y_pred_f =tf.reshape(y_pred,-1)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f,0)\n",
    "\n",
    "    return float((2. * intersection+smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f)+smooth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a856ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_coef(y_true, y_pred,smooth=1):\n",
    "  intersection = tf.reduce_sum(y_true * y_pred, 0)\n",
    "  union = tf.reduce_sum(y_true,0)+tf.reduce_sum(y_pred,0)-intersection\n",
    "  iou = tf.reduce_mean((intersection+1) / (union+1), 0)\n",
    "  return float(iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9e46c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_exp = [(\"count\",i) for i in range(2,5)]\n",
    "keep_percents_exp = [(\"keep_percent\",i/10) for i in range(1,5)]\n",
    "train_sizes_exp = [(\"train_size\",i*2000) for i in range(1,4)]\n",
    "res_exp = []#[(\"res\",2**i) for i in range(6,9)]\n",
    "experiments = counts_exp + keep_percents_exp + train_sizes_exp + res_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb70530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd9f3bce59b4cd0b918d192014db906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_percent 0.2810913475705226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-1d86426b1e64>:16: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  record = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanimg.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "Starting level 0\n",
      "Completing 64.0\n",
      "pca shape tf.Tensor([27 27], shape=(2,), dtype=int32)\n",
      "keep_channels 7 keep_max 12.0\n",
      "keep_channels 7\n",
      "ufilts.shape (1, 1, 1, 27, 7)\n",
      "end loop 64.0\n",
      "Starting level 1\n",
      "Completing 32.0\n",
      "pca shape tf.Tensor([63 63], shape=(2,), dtype=int32)\n",
      "keep_channels 17 keep_max 112.0\n",
      "keep_channels 17\n",
      "ufilts.shape (1, 1, 1, 63, 17)\n",
      "end loop 32.0\n",
      "saving to: models/pets_img\n",
      "out.shape (1, 32, 32, 17)\n",
      "keep_percent 0.2810913475705226\n",
      "meanimg.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "Starting level 0\n",
      "Completing 64.0\n",
      "pca shape tf.Tensor([27 27], shape=(2,), dtype=int32)\n",
      "keep_channels 7 keep_max 12.0\n",
      "keep_channels 7\n",
      "ufilts.shape (1, 1, 1, 27, 7)\n",
      "end loop 64.0\n",
      "Starting level 1\n",
      "Completing 32.0\n",
      "pca shape tf.Tensor([63 63], shape=(2,), dtype=int32)\n",
      "keep_channels 17 keep_max 112.0\n",
      "keep_channels 17\n",
      "ufilts.shape (1, 1, 1, 63, 17)\n",
      "end loop 32.0\n",
      "sample.shape (128, 128, 3)\n",
      "after reshape: sample.shape (1, 128, 128, 3)\n",
      "loading from: models/pets_img\n",
      "out.shape (1, 32, 32, 17)\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(128, 128, 3), dtype=float64, numpy=\n",
      "array([[[0.96515107, 0.93393552, 0.91092509],\n",
      "        [0.87081516, 0.80595565, 0.79187489],\n",
      "        [0.86642015, 0.82180369, 0.79532158],\n",
      "        ...,\n",
      "        [0.87063849, 0.82426375, 0.78263777],\n",
      "        [0.87352365, 0.82447964, 0.79275811],\n",
      "        [0.92949313, 0.89744228, 0.88557947]],\n",
      "\n",
      "       [[0.79790419, 0.68389052, 0.64531207],\n",
      "        [0.46615493, 0.18274452, 0.15653101],\n",
      "        [0.44881091, 0.19862564, 0.15095837],\n",
      "        ...,\n",
      "        [0.62600482, 0.32333842, 0.20385215],\n",
      "        [0.56797886, 0.26039273, 0.1665628 ],\n",
      "        [0.82270169, 0.72857165, 0.68948424]],\n",
      "\n",
      "       [[0.78860247, 0.64573139, 0.60463631],\n",
      "        [0.29589367, 0.04779268, 0.03921569],\n",
      "        [0.44276914, 0.14519331, 0.0877092 ],\n",
      "        ...,\n",
      "        [0.60813946, 0.29297164, 0.14303529],\n",
      "        [0.70828694, 0.45093444, 0.32121632],\n",
      "        [0.81302035, 0.73581445, 0.68740761]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.7795037 , 0.67046571, 0.654024  ],\n",
      "        [0.26556277, 0.05079561, 0.04123727],\n",
      "        [0.27025986, 0.04306497, 0.03977817],\n",
      "        ...,\n",
      "        [0.2844291 , 0.03921569, 0.03921569],\n",
      "        [0.57108086, 0.31786248, 0.31051001],\n",
      "        [0.87000614, 0.81167281, 0.80242032]],\n",
      "\n",
      "       [[0.77211821, 0.65440941, 0.64795738],\n",
      "        [0.35603413, 0.06950397, 0.06653215],\n",
      "        [0.35900736, 0.06464557, 0.06418553],\n",
      "        ...,\n",
      "        [0.35569614, 0.06997501, 0.05775027],\n",
      "        [0.36838093, 0.07885886, 0.0666346 ],\n",
      "        [0.87770849, 0.82493252, 0.82075959]],\n",
      "\n",
      "       [[0.92029911, 0.87912643, 0.86998028],\n",
      "        [0.77874446, 0.66883618, 0.65827256],\n",
      "        [0.77500004, 0.67722648, 0.67237574],\n",
      "        ...,\n",
      "        [0.81860733, 0.72755343, 0.71955711],\n",
      "        [0.80129921, 0.72139722, 0.70963252],\n",
      "        [0.96722579, 0.95742381, 0.95013022]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(128, 128, 3), dtype=float64, numpy=\n",
      "array([[[0.96515107, 0.93393552, 0.91092509],\n",
      "        [0.87081516, 0.80595565, 0.79187489],\n",
      "        [0.86642015, 0.82180369, 0.79532158],\n",
      "        ...,\n",
      "        [0.87063849, 0.82426375, 0.78263777],\n",
      "        [0.87352365, 0.82447964, 0.79275811],\n",
      "        [0.92949313, 0.89744228, 0.88557947]],\n",
      "\n",
      "       [[0.79790419, 0.68389052, 0.64531207],\n",
      "        [0.46615493, 0.18274452, 0.15653101],\n",
      "        [0.44881091, 0.19862564, 0.15095837],\n",
      "        ...,\n",
      "        [0.62600482, 0.32333842, 0.20385215],\n",
      "        [0.56797886, 0.26039273, 0.1665628 ],\n",
      "        [0.82270169, 0.72857165, 0.68948424]],\n",
      "\n",
      "       [[0.78860247, 0.64573139, 0.60463631],\n",
      "        [0.29589367, 0.04779268, 0.03921569],\n",
      "        [0.44276914, 0.14519331, 0.0877092 ],\n",
      "        ...,\n",
      "        [0.60813946, 0.29297164, 0.14303529],\n",
      "        [0.70828694, 0.45093444, 0.32121632],\n",
      "        [0.81302035, 0.73581445, 0.68740761]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.7795037 , 0.67046571, 0.654024  ],\n",
      "        [0.26556277, 0.05079561, 0.04123727],\n",
      "        [0.27025986, 0.04306497, 0.03977817],\n",
      "        ...,\n",
      "        [0.2844291 , 0.03921569, 0.03921569],\n",
      "        [0.57108086, 0.31786248, 0.31051001],\n",
      "        [0.87000614, 0.81167281, 0.80242032]],\n",
      "\n",
      "       [[0.77211821, 0.65440941, 0.64795738],\n",
      "        [0.35603413, 0.06950397, 0.06653215],\n",
      "        [0.35900736, 0.06464557, 0.06418553],\n",
      "        ...,\n",
      "        [0.35569614, 0.06997501, 0.05775027],\n",
      "        [0.36838093, 0.07885886, 0.0666346 ],\n",
      "        [0.87770849, 0.82493252, 0.82075959]],\n",
      "\n",
      "       [[0.92029911, 0.87912643, 0.86998028],\n",
      "        [0.77874446, 0.66883618, 0.65827256],\n",
      "        [0.77500004, 0.67722648, 0.67237574],\n",
      "        ...,\n",
      "        [0.81860733, 0.72755343, 0.71955711],\n",
      "        [0.80129921, 0.72139722, 0.70963252],\n",
      "        [0.96722579, 0.95742381, 0.95013022]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(128, 128, 3), dtype=float64, numpy=\n",
      "array([[[0.04227678, 0.06537727, 0.03921569],\n",
      "        [0.06662023, 0.11495649, 0.05612745],\n",
      "        [0.03921569, 0.05370926, 0.03921569],\n",
      "        ...,\n",
      "        [0.03921569, 0.0662837 , 0.03921569],\n",
      "        [0.03921569, 0.05812677, 0.03921569],\n",
      "        [0.03921569, 0.0575394 , 0.03921569]],\n",
      "\n",
      "       [[0.03921569, 0.05390529, 0.03921569],\n",
      "        [0.15582132, 0.20696758, 0.10521695],\n",
      "        [0.04115062, 0.06445336, 0.03921569],\n",
      "        ...,\n",
      "        [0.03921569, 0.06420276, 0.03921569],\n",
      "        [0.03921569, 0.05081332, 0.03921569],\n",
      "        [0.03921569, 0.04375838, 0.03921569]],\n",
      "\n",
      "       [[0.04127724, 0.04414398, 0.03921569],\n",
      "        [0.16459315, 0.24875201, 0.12933445],\n",
      "        [0.05768756, 0.09986261, 0.04812539],\n",
      "        ...,\n",
      "        [0.03921569, 0.0641221 , 0.03921569],\n",
      "        [0.03921569, 0.05971201, 0.03921569],\n",
      "        [0.04267554, 0.08517373, 0.03921569]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.36728755, 0.56087774, 0.28557298],\n",
      "        [0.29968479, 0.52660608, 0.18709932],\n",
      "        [0.18146782, 0.37489495, 0.08235964],\n",
      "        ...,\n",
      "        [0.37482169, 0.59304368, 0.25572559],\n",
      "        [0.39168006, 0.613271  , 0.180969  ],\n",
      "        [0.31647518, 0.4966529 , 0.19797173]],\n",
      "\n",
      "       [[0.41381022, 0.60750687, 0.28956324],\n",
      "        [0.36164361, 0.5804745 , 0.2480239 ],\n",
      "        [0.20232604, 0.36597422, 0.13123612],\n",
      "        ...,\n",
      "        [0.34234762, 0.45251489, 0.20975031],\n",
      "        [0.23821113, 0.42227858, 0.11680694],\n",
      "        [0.27650648, 0.42136544, 0.17944504]],\n",
      "\n",
      "       [[0.46400052, 0.55404824, 0.35764712],\n",
      "        [0.38519382, 0.61312211, 0.27429298],\n",
      "        [0.0692189 , 0.08644613, 0.0579463 ],\n",
      "        ...,\n",
      "        [0.63060999, 0.79433739, 0.57818747],\n",
      "        [0.45994803, 0.64438742, 0.36449477],\n",
      "        [0.27144969, 0.43803281, 0.12867048]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor: shape=(128, 128, 3), dtype=float64, numpy=\n",
      "array([[[0.04227678, 0.06537727, 0.03921569],\n",
      "        [0.06662023, 0.11495649, 0.05612745],\n",
      "        [0.03921569, 0.05370926, 0.03921569],\n",
      "        ...,\n",
      "        [0.03921569, 0.0662837 , 0.03921569],\n",
      "        [0.03921569, 0.05812677, 0.03921569],\n",
      "        [0.03921569, 0.0575394 , 0.03921569]],\n",
      "\n",
      "       [[0.03921569, 0.05390529, 0.03921569],\n",
      "        [0.15582132, 0.20696758, 0.10521695],\n",
      "        [0.04115062, 0.06445336, 0.03921569],\n",
      "        ...,\n",
      "        [0.03921569, 0.06420276, 0.03921569],\n",
      "        [0.03921569, 0.05081332, 0.03921569],\n",
      "        [0.03921569, 0.04375838, 0.03921569]],\n",
      "\n",
      "       [[0.04127724, 0.04414398, 0.03921569],\n",
      "        [0.16459315, 0.24875201, 0.12933445],\n",
      "        [0.05768756, 0.09986261, 0.04812539],\n",
      "        ...,\n",
      "        [0.03921569, 0.0641221 , 0.03921569],\n",
      "        [0.03921569, 0.05971201, 0.03921569],\n",
      "        [0.04267554, 0.08517373, 0.03921569]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.36728755, 0.56087774, 0.28557298],\n",
      "        [0.29968479, 0.52660608, 0.18709932],\n",
      "        [0.18146782, 0.37489495, 0.08235964],\n",
      "        ...,\n",
      "        [0.37482169, 0.59304368, 0.25572559],\n",
      "        [0.39168006, 0.613271  , 0.180969  ],\n",
      "        [0.31647518, 0.4966529 , 0.19797173]],\n",
      "\n",
      "       [[0.41381022, 0.60750687, 0.28956324],\n",
      "        [0.36164361, 0.5804745 , 0.2480239 ],\n",
      "        [0.20232604, 0.36597422, 0.13123612],\n",
      "        ...,\n",
      "        [0.34234762, 0.45251489, 0.20975031],\n",
      "        [0.23821113, 0.42227858, 0.11680694],\n",
      "        [0.27650648, 0.42136544, 0.17944504]],\n",
      "\n",
      "       [[0.46400052, 0.55404824, 0.35764712],\n",
      "        [0.38519382, 0.61312211, 0.27429298],\n",
      "        [0.0692189 , 0.08644613, 0.0579463 ],\n",
      "        ...,\n",
      "        [0.63060999, 0.79433739, 0.57818747],\n",
      "        [0.45994803, 0.64438742, 0.36449477],\n",
      "        [0.27144969, 0.43803281, 0.12867048]]])>]\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keep_percent 0.2810913475705226\n",
      "meanimg.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "self.mean.dtype <dtype: 'float64'>\n",
      "Starting level 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_size = 300\n",
    "\n",
    "#These are the standard experiment settings\n",
    "activity_regularizer = scaledtanh\n",
    "inverse_activity_regularizer = scaledatanh\n",
    "count = 3\n",
    "keep_percent = 0.4\n",
    "train_size = None\n",
    "res = 128\n",
    "dataset = \"pets\"\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for settings in tqdm.notebook.tqdm(experiments):\n",
    "    \n",
    "    record = pd.Series()\n",
    "    \n",
    "    variable, value = settings\n",
    "    if variable == \"count\":\n",
    "        count = value\n",
    "    if variable == \"keep_percent\":\n",
    "        keep_percent = value\n",
    "    if variable == \"train_size\":\n",
    "        train_size = value\n",
    "    if variable == \"res\":\n",
    "        resolution = value\n",
    "\n",
    "    loader = dl.DataLoader(IMAGE_SIZE=res,dataset=dataset,take=train_size)\n",
    "    img_ds = loader.import_processed_img()\n",
    "    seg_ds = loader.import_processed_seg()\n",
    "    cardinality = int(img_ds.cardinality())\n",
    "\n",
    "    img_test = img_ds.take(test_size)\n",
    "    seg_test = seg_ds.take(test_size)\n",
    "    img_train = img_ds.skip(test_size)\n",
    "    seg_train = seg_ds.skip(test_size)    \n",
    "    \n",
    "    record[\"count\"]=count\n",
    "    record[\"keep_percent\"] = keep_percent\n",
    "    record[\"activity_regularizer\"] = activity_regularizer != None\n",
    "    record[\"training_data_size\"] = train_size\n",
    "    \n",
    "    img_train_start = time.time()\n",
    "    imghead, imginvhead,stats = build_model_instance(img_train,img_test,dataset,\"img\",keep_percent = keep_percent,count=count,check_build=True)\n",
    "    psnr_train,ncc_train,psnr_test,ncc_test = stats\n",
    "    img_train_end = time.time()\n",
    "    \n",
    "    record[\"img_channel_size\"] = imghead(next(iter(img_train))[0]).shape[-1]\n",
    "    record[\"img_train_time\"] = img_train_end - img_train_start\n",
    "    record[\"train_img_psnr\"] = psnr_train\n",
    "    record[\"train_img_ncc\"] = ncc_train\n",
    "    record[\"test_img_psnr\"] = psnr_test\n",
    "    record[\"test_img_ncc\"] = ncc_test\n",
    "    \n",
    "    seg_train_start = time.time()\n",
    "    seghead, seginvhead,stats = build_model_instance(seg_train,seg_test,dataset,\"seg\",count=count,keep_percent = keep_percent,check_build=True)\n",
    "    psnr_train,ncc_train,psnr_test,ncc_test = stats\n",
    "    seg_train_end = time.time()\n",
    "    \n",
    "    record[\"seg_channel_size\"] = seghead(next(iter(seg_train))[0]).shape[-1]\n",
    "    record[\"seg_train_time\"] = img_train_end - img_train_start\n",
    "    record[\"train_seg_psnr\"] = psnr_train\n",
    "    record[\"train_seg_ncc\"] = ncc_train\n",
    "    record[\"test_seg_psnr\"] = psnr_test\n",
    "    record[\"test_seg_ncc\"] = ncc_test\n",
    "    \n",
    "    train_time_start = time.time()\n",
    "    A,b = calculate_A_and_b(imghead,seghead,img_train,seg_train)\n",
    "    train_time_end = time.time()\n",
    "    \n",
    "    record[\"linear_inverse_train_time\"] = train_time_end - train_time_start \n",
    "    \n",
    "    dice_mean_test, iou_mean_test, dice_std_test, iou_std_test = calculate_metrics(seg_test,img_test,imghead,seghead,seginvhead)\n",
    "    dice_mean_train, iou_mean_train, dice_std_train, iou_std_train = calculate_metrics(seg_train,img_train,imghead,seghead,seginvhead)\n",
    "    \n",
    "    record[\"dice_mean_train\"] = dice_mean_train\n",
    "    record[\"iou_mean_train\"] = iou_mean_train\n",
    "    record[\"dice_std_train\"] = dice_std_train\n",
    "    record[\"iou_std_train\"] = iou_std_train\n",
    "    record[\"dice_mean_test\"] = dice_mean_test\n",
    "    record[\"iou_mean_test\"] = iou_mean_test\n",
    "    record[\"dice_std_test\"] = dice_std_test\n",
    "    record[\"iou_std_test\"] = iou_std_test\n",
    "    df = df.append(record,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"formal_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e7dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "reconstruct = seghead(next(iter(seg_train))[0]).shape\n",
    "threshold_intensity = 0.01\n",
    "skip = random.randint(0,70)\n",
    "image,seg_base = next(iter(zip(img_test.skip(skip),seg_test.skip(skip))))\n",
    "imgdecom = imghead(image[0])\n",
    "imgdecom = tf.reshape(imgdecom,(1,-1))\n",
    "segdecom = tf.linalg.matvec(A,imgdecom,transpose_a=True)+b\n",
    "seg = seginvhead(tf.reshape(segdecom,(reconstruct)))\n",
    "y_true = tf.cast(tf.reduce_min(seg_base[0],2)==0,tf.float64)\n",
    "y_pred = tf.cast(tf.reduce_min(seg[0],2)<threshold_intensity,tf.float64)\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(np.hstack([image[0],seg_base[0],seg[0]]))\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(np.hstack([y_true,y_pred]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7b1d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
