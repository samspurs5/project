{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df594f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras as K\n",
    "from keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tf.keras.backend.set_floatx(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed21cfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "\n",
    "    ds_train,info = tfds.load('caltech_birds2010', split='train',with_info=True)\n",
    "    ds_test,info = tfds.load('caltech_birds2010', split='test',with_info=True)\n",
    "    \n",
    "    return ds_train,ds_test,info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ce9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_raw,ds_test_raw,info = import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ecb4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128\n",
    "def pre_process_image(record):\n",
    "    \n",
    "    image = record[\"image\"]\n",
    "    image = image / 255\n",
    "    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    seg_image = record[\"segmentation_mask\"]\n",
    "    seg_image = tf.image.resize(seg_image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    seg_image = tf.cast(seg_image, tf.float32)\n",
    "    return image,seg_image\n",
    "\n",
    "resize_train = ds_train_raw.map(pre_process_image)\n",
    "\n",
    "resize_test = ds_test_raw.map(pre_process_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74f76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7058c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(next(iter(resize_train))[0].shape, name=\"input_img\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8474fa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.backend.flatten(y_true)\n",
    "    y_pred_f = K.backend.flatten(y_pred)\n",
    "    intersection = K.backend.sum(y_true_f * y_pred_f)\n",
    "\n",
    "    return (2. * intersection) / (K.backend.sum(y_true_f) + K.backend.sum(y_pred_f))\n",
    "\n",
    "def diceCoefLoss(y_true, y_pred):\n",
    "    return (1-dice_coef(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5c2da8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "decoded = Conv2D(1, (2, 2), activation='sigmoid', padding='same',name=\"decoded\")(x)\n",
    "    \n",
    "autoencoder = K.Model(input_img, decoded)\n",
    "optimizer = K.optimizers.adam_v2.Adam(learning_rate=1e-6)\n",
    "autoencoder.compile(optimizer=optimizer, loss=diceCoefLoss,metrics=[K.metrics.MeanIoU(num_classes=2),dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2c336b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_img (InputLayer)      [(None, 128, 128, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 128, 128, 8)       224       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 64, 64, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 64, 64, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 32, 32, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 32, 32, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 16, 16, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " up_sampling2d_12 (UpSamplin  (None, 32, 32, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 32, 32, 32)        18464     \n",
      "                                                                 \n",
      " up_sampling2d_13 (UpSamplin  (None, 64, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 64, 64, 16)        4624      \n",
      "                                                                 \n",
      " up_sampling2d_14 (UpSamplin  (None, 128, 128, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 128, 128, 8)       1160      \n",
      "                                                                 \n",
      " decoded (Conv2D)            (None, 128, 128, 1)       33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,809\n",
      "Trainable params: 48,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6042deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    K.callbacks.ModelCheckpoint(\"../bird_autoencoder.h5\", save_best_only=True, monitor=\"val_dice_coef\",mode=\"max\")\n",
    "]\n",
    "\n",
    "# Train the model, doing validation at the end of each epoch.\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2634daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = resize_train.batch(64).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = resize_test.batch(64).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ab8a6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 128, 128, 3), (None, 128, 128, 1)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec316177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47/47 - 273s - loss: 0.7407 - mean_io_u_3: 0.4168 - dice_coef: 0.2593 - val_loss: 0.7523 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2472 - 273s/epoch - 6s/step\n",
      "Epoch 2/20\n",
      "47/47 - 314s - loss: 0.7401 - mean_io_u_3: 0.4168 - dice_coef: 0.2599 - val_loss: 0.7517 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2478 - 314s/epoch - 7s/step\n",
      "Epoch 3/20\n",
      "47/47 - 325s - loss: 0.7395 - mean_io_u_3: 0.4168 - dice_coef: 0.2605 - val_loss: 0.7512 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2484 - 325s/epoch - 7s/step\n",
      "Epoch 4/20\n",
      "47/47 - 273s - loss: 0.7389 - mean_io_u_3: 0.4168 - dice_coef: 0.2611 - val_loss: 0.7506 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2490 - 273s/epoch - 6s/step\n",
      "Epoch 5/20\n",
      "47/47 - 296s - loss: 0.7383 - mean_io_u_3: 0.4168 - dice_coef: 0.2618 - val_loss: 0.7500 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2495 - 296s/epoch - 6s/step\n",
      "Epoch 6/20\n",
      "47/47 - 320s - loss: 0.7376 - mean_io_u_3: 0.4168 - dice_coef: 0.2624 - val_loss: 0.7494 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2501 - 320s/epoch - 7s/step\n",
      "Epoch 7/20\n",
      "47/47 - 328s - loss: 0.7370 - mean_io_u_3: 0.4168 - dice_coef: 0.2631 - val_loss: 0.7488 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2508 - 328s/epoch - 7s/step\n",
      "Epoch 8/20\n",
      "47/47 - 301s - loss: 0.7363 - mean_io_u_3: 0.4168 - dice_coef: 0.2637 - val_loss: 0.7481 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2514 - 301s/epoch - 6s/step\n",
      "Epoch 9/20\n",
      "47/47 - 299s - loss: 0.7356 - mean_io_u_3: 0.4168 - dice_coef: 0.2644 - val_loss: 0.7475 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2520 - 299s/epoch - 6s/step\n",
      "Epoch 10/20\n",
      "47/47 - 294s - loss: 0.7349 - mean_io_u_3: 0.4168 - dice_coef: 0.2651 - val_loss: 0.7468 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2527 - 294s/epoch - 6s/step\n",
      "Epoch 11/20\n",
      "47/47 - 297s - loss: 0.7342 - mean_io_u_3: 0.4168 - dice_coef: 0.2658 - val_loss: 0.7462 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2534 - 297s/epoch - 6s/step\n",
      "Epoch 12/20\n",
      "47/47 - 289s - loss: 0.7335 - mean_io_u_3: 0.4168 - dice_coef: 0.2666 - val_loss: 0.7455 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2541 - 289s/epoch - 6s/step\n",
      "Epoch 13/20\n",
      "47/47 - 307s - loss: 0.7327 - mean_io_u_3: 0.4168 - dice_coef: 0.2673 - val_loss: 0.7448 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2548 - 307s/epoch - 7s/step\n",
      "Epoch 14/20\n",
      "47/47 - 291s - loss: 0.7320 - mean_io_u_3: 0.4168 - dice_coef: 0.2681 - val_loss: 0.7440 - val_mean_io_u_3: 0.4217 - val_dice_coef: 0.2555 - 291s/epoch - 6s/step\n",
      "Epoch 15/20\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(ds_train,validation_data=ds_test,epochs=epochs,verbose=2,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8bcfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"loss\"],label= \"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009a5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
